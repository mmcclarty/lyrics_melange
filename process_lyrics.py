# $Id: process_lyrics.py 8163 2018-04-02 21:16:30Z milde $
# Author: Megan McClarty <https://github.com/mcclarty>

import string 
import nltk
import io
import pandas as pd
nltk.download('stopwords')
nltk.download('punkt')
from nltk.corpus import stopwords
from nltk.tokenize import wordpunct_tokenize
from nltk.classify import NaiveBayesClassifier
from nltk.corpus import subjectivity
from nltk.sentiment import SentimentAnalyzer
from nltk.sentiment.util import *
from nltk.sentiment.vader import SentimentIntensityAnalyzer
from sklearn.model_selection import train_test_split

'''
The text files of lyrics must be generated by running api_conn.py. English and French lyrics will be written to separate text files entitled
EN.txt and FR.txt, respectively. 

The lists of English and French stopwords are bundled into the NLTK corpus.  The lists of swear words/profanity in both English and French 
are taken from https://github.com/LDNOOBW/List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words, used for filtering spam at Shutterstock.
'''


# Split compiled lyrics files into discreet words (tokenize)
def read_words(words_file):
    into_words = [word for line in io.open(words_file, 'r') for word in line.split()]
    return into_words


# Split the space-separated text file into discreet lines
def swear_words(swear_file):
    swear_words = [line.rstrip() for line in open(swear_file, 'r')]
    return swear_words

# Filter out stopwords (for future work in sentiment analysis), remove punctuation 
def filter_lyrics(rap_lyrics, stop_words):
    filtered_lyrics = [w.lower() for w in rap_lyrics if not w in stop_words]
    filtered_lyrics = []
    for w in rap_lyrics:
        if w.lower() not in stop_words:
            filtered_lyrics.append(w.lower())
            
    remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)
    no_punc = [s.translate(remove_punctuation_map) for s in filtered_lyrics]

    return no_punc


# Extract profanity from lyrics set and make dictionary counting each appearance 
def filter_swears(filtered, swear_list):
    rap_swears = [w for w in filtered if w in swear_list]

    swear_dict = {}
    for word in rap_swears:
        swear_dict[word] = swear_dict.get(word, 0) + 1

    return swear_dict


def sentiment_analysis(rap_lyrics):
    # Create dataframe of open source English word sentiments
    lexicon = pd.read_csv('subjclueslen1-HLTEMNLP05.txt', sep=' ', header=None, error_bad_lines=False)
    lexdf = pd.DataFrame(lexicon)

    # Title columns for easier analysis
    list = [0, 1, 2, 3, 4, 5]
    titles = ['Type', 'Length', 'Word', 'Pos', 'Stemmed', 'Priorpolarity']
    for i, j in zip(list, titles):
        lexdf[j] = lexdf[i].apply(lambda s: s.split('=')[1])
    lexdf = lexdf.drop([0, 1, 2, 3, 4, 5], axis=1)
    print(lexdf.head())

    train_lyrics, test_lyrics = train_test_split(rap_lyrics, test_size=0.2)


def main():
    en_rap_lyrics = read_words('EN.txt')
    fr_rap_lyrics = read_words('FR.txt')

    en_stop_words = set(stopwords.words('english'))
    fr_stop_words = set(stopwords.words('french'))
    english_swears = swear_words('en')
    french_swears = swear_words('fr')

    en_filtered = filter_lyrics(en_rap_lyrics, en_stop_words)
    endist = nltk.FreqDist(en_filtered)
    fr_filtered = filter_lyrics(fr_rap_lyrics, fr_stop_words)
    frdist = nltk.FreqDist(fr_filtered)
    for word, freq in zip(endist.most_common(15), frdist.most_common(15)):
        print(u'{}:{}'.format(word, freq))

    sentiment_analysis(en_filtered)

    en_swear_dict = filter_swears(en_filtered, english_swears)
    fr_swear_dict = filter_swears(fr_filtered, french_swears)

    print(en_swear_dict)
    print(fr_swear_dict)


main()



